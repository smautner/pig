{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e20f7-d090-4992-a99a-5c02f77a7613",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import smallgraph as sg\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import lmz\n",
    "import eden.graph as eg\n",
    "import eden.display as ed\n",
    "from yoda.graphs import ali2graph\n",
    "import numpy as np\n",
    "import yoda.ml.simpleMl as sml\n",
    "import eden.display as ed\n",
    "from yoda.alignments import load_rfam, filter_by_seqcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0e4bac-4829-4074-963d-6b62f1782edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from kiez import Kiez \n",
    "from ubergauss import tools as ut\n",
    "from ubergauss import optimization as op\n",
    "import yoda.ml.simpleMl as sml\n",
    "from yoda.graphs import alignment_to_vectors\n",
    "import yoda.ml.distances as yodadist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cff557-7df8-4a60-977d-2368ab073946",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = '''min_r 0 3 1\n",
    "min_d 0 3 1\n",
    "fix_edges 0 1 1\n",
    "ct .88 1\n",
    "d1 0 1\n",
    "d2 0 1\n",
    "nest 0 1 1\n",
    "kiezK 23 30 1\n",
    "kiezMethod 0 5 1\n",
    "simplegraph 0 1 1\n",
    "bad_weight 0 .3'''\n",
    "\n",
    "# clusterSize 0 40 5\n",
    "# a,l, te = sg.makedata()\n",
    "\n",
    "#eval(a,l,**{'min_d': 2, 'nest': 1})\n",
    "# a,l = sg.makedata(splits=0)\n",
    "# matrix = alignment_to_vectors(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12adebcc-777c-456b-9415-19272f7e5e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sg.makedata(splits=2)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34601c55b65126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ubergauss.optimization import nutype,gatype\n",
    "import optihelper as oh\n",
    "import copy\n",
    "o = nutype.nutype(space, oh.eval, [data], numsample=16)\n",
    "o.opti()\n",
    "print(n.NU)\n",
    "# Best params: {'bad_weight': 0.1607173103329372, 'ct': 0.9110921699651566, 'd1': 0.6318627398862378, 'd2': 0.2554687630753362, 'fix_edges': 1.0, 'kiezK': 28.0, 'kiezMethod': 2.0, 'min_d': 3.0, 'min_r': 1.0, 'nest': 1.0, 'simplegraph': 0.0, 'datafield': 0.0, 'score': 0.6124208382137607, 'time': 64.91160798072815}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ede3f0e-0483-4f8b-9d14-0356e25c3ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(o.NU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d3bf5-7867-4248-ae34-4cb631c1247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = copy.deepcopy(o)\n",
    "z.opti()\n",
    "z.nuParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9847cca4-1111-48d5-99b9-bf867346ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.opti()\n",
    "o.opti()\n",
    "o.opti()\n",
    "o.opti()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab24f89-44f3-49b1-84f4-b6364ab7a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "o.opti()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b969c5b-4476-4505-842d-52cd4d12e962",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.nuParams()\n",
    "o.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4d465-4595-4914-b117-5f41c941d3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "o.nuParams(o.df)\n",
    "def plot_params_with_hist(params, df):\n",
    "    for col in params.columns:\n",
    "        if col == \"score\":\n",
    "            continue  # Skip the score column itself\n",
    "\n",
    "        fig, ax1 = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "        # Lineplot: param vs score\n",
    "        sns.lineplot(x=col, y=\"score\", data=df, ax=ax1, color='blue', label='Score')\n",
    "        ax1.set_ylabel(\"Score\", color='blue')\n",
    "        ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "        # Histogram: distribution of values in df\n",
    "        ax2 = ax1.twinx()\n",
    "        sns.histplot(params[col], ax=ax2, color='gray', alpha=0.3, bins=20, label='Distribution')\n",
    "        ax2.set_ylabel(\"Frequency\", color='gray')\n",
    "        ax2.tick_params(axis='y', labelcolor='gray')\n",
    "\n",
    "        # Titles and layout\n",
    "        plt.title(f\"{col} vs Score with Distribution Overlay\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "plot_params_with_hist(pd.DataFrame(o.params), o.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baba8bc655c1095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# space = sg.string_to_space(yodadist.params)\n",
    "\n",
    "# kiezPresort 0 150 1\n",
    "space = sg.string_to_space(space)\n",
    "parameters = [space.sample() for i in range(500)]\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3628c1dd8259f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = sg.makedata(splits=2)[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546231e3dfa3ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optihelper as oh\n",
    "#results = op.gridsearch(eval, tasks =  parameters , data=(a,l,matrix), mp=True)\n",
    "results= op.gridsearch(oh.eval,  data_list =[data],tasks = parameters, mp=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364455eb-c0ee-4043-bb02-ba85d7943ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f06d53-8938-4de2-9d37-b0c786ccb27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.parallel_coordinates(results, 'score', colormap = 'magma')\n",
    "plt.legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1f029a-3f30-4791-912e-8aa253aacc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.to_csv('rando.csv')\n",
    "!head rando.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a91bbb9-5020-4e75-8a8f-ddffdb165a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp(results.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c707f51fc74ae75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.corr()\n",
    "sns.pairplot(results, hue='score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a31489bbf075974",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by='score', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31adb633f689ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pop('time')\n",
    "results.pop('datafield')\n",
    "results.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da42cd043ae2a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sns.pairplot(results, hue='score')\n",
    "results.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a4189-f221-435a-b454-d0703308a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "datas  = [sg.makedata(splits=3)[:2]]\n",
    "\n",
    "\n",
    "# datas   = [sg.makedata(splits=3)[:2] for x in range(3) ]\n",
    "# datas = [(ali2graph.multiGraph(a),l) for a,l in datas ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b9640a-80d7-4325-be0c-7ee9b8a91301",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {'clusterSize':10, 'simplegraph':0 , 'maxclust':10, 'fix_edges':True}\n",
    "eval(*datas[0], **parameters)\n",
    "# 475"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fd8977-15f4-40e0-9697-b6ec83b462eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {'clusterSize':[0,15], 'simplegraph':[0,1] , 'maxclust':[10]}\n",
    "# results = [op.gridsearch(eval, tasks =  parameters , data=data, mp=True)  for data in datas]\n",
    "\n",
    "results = op.gridsearch(eval, param_dict =  parameters , data=datas[0], mp=True)\n",
    "# results = [ op.gridsearch(eval, param_dict =  parameters , data=data , mp=True) for data in datas];results = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb86ac-7248-4640-856d-0817911e1670",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    resultsXX = pd.concat(resultsXXX+results4)\n",
    "    results5c = pd.concat(results5)\n",
    "    sns.pairplot(resultsXX)\n",
    "    resultsXX.sort_values(by='csls', ascending=False).head(20)\n",
    "    sns.lineplot(resultsXX, x= 'clusterSize', y='csls',label= 'conserved columns weighted')\n",
    "    sns.lineplot(results5c, x= 'clusterSize', y='csls', label='unweighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f9354-347c-4489-8b5b-c084dca7aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.concat(results)\n",
    "results.sort_values(by='csls', ascending=False).head(20)\n",
    "\n",
    "sns.lineplot(results, x= 'clusterSize', y='csls', hue= 'simplegraph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea522e6c-7a41-4418-9d68-43abe80d5473",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.pairplot(results, hue='score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80116398-4a3f-411f-9eb1-b59eb8de9ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de87695c-7062-4b8c-bf22-9d309f7010d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_dict = sg.string_to_space(space)\n",
    "parameters = [space_dict.sample() for i in range(2)]\n",
    "data = sg.makedata(splits=0)\n",
    "results = op.gridsearch(eval, tasks =  parameters , data=data, mp=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43327b1-3802-4980-92e5-4beaac9e87f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by='csls', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0505ac2b-b680-4c95-8b9f-9d3a9c08b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for column in hub_methods:  # Replace with your actual column names\n",
    "    sns.kdeplot(data=results[column], label=column)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8fe03e-da9b-4bce-b273-7529b34dfd14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c787f5f-3ae7-4b0f-8f71-144f2fd47643",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "space = '''d1 0 1\n",
    "d2 0 1\n",
    "'''\n",
    "\n",
    "# a,l, te = sg.makedata()\n",
    "\n",
    "#eval(a,l,**{'min_d': 2, 'nest': 1})\n",
    "space_dict = sg.string_to_space(space)\n",
    "parameters = [space_dict.sample() for i in range(100)]\n",
    "data = sg.makedata(splits=0)\n",
    "for t in parameters:\n",
    "    t['hub_methods']=['csls']\n",
    "results = op.gridsearch(eval, tasks =  parameters , data=data, mp=True) \n",
    "results.sort_values(by='csls', ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c715dd1-5681-48da-be51-17d0b70064a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd1268e-31b3-48be-9f34-c047dd67733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by='csls', ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0cdf1f-eb22-4f90-b9b9-586be4276d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rank_columns_and_average(df, columns):\n",
    "    # Subset the dataframe to include only the specified columns\n",
    "    subset_df = df[columns]\n",
    "    # Rank the values row-wise\n",
    "    ranked_df = subset_df.rank(axis=1)\n",
    "    # Calculate the average rank for each column\n",
    "    avg_ranks = ranked_df.mean().to_dict()\n",
    "    # Create a list of pairs (column name, average rank)\n",
    "    result = [(col, avg_ranks[col]) for col in columns]\n",
    "    return result\n",
    "\n",
    "\n",
    "rank_columns_and_average(results,['csls', 'dissimlocal', 'localscaling', 'mutualproximity', 'norm', 'no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7981ba24-81ab-4f37-a069-88d0cfb902a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6355db-a0de-46b9-950b-39217946257a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b001baea-8e53-4745-8d78-f342b1cde023",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = [sg.makedata() for i in range(REPEATS)]\n",
    "datasets = [d[:2] for d in data_all]\n",
    "test_sets = [d[2] for d in data_all]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af727ab7-0f17-49b6-b9f2-79832306bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets, datasets = datasets, test_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323355d8-b74b-4058-b0cd-1aa6481369ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = sg.string_to_space(space)\n",
    "parameters = [space.sample() for i in range(PARAMS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e26bed-aed2-4a5a-ba76-d8f0345bd411",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = [ op.gridsearch(eval, parameters , tasks = parameters , data= [a,l], mp=True)  for a,l in datasets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba908a-8870-4993-9a12-789a359f5dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c498c943-3a81-471b-9cdc-0c40fc1c70ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f784bb-fadd-43bd-852d-0d59b96cc32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_error(results):\n",
    "    for i,df in enumerate(results):\n",
    "        # in all the dfs, we only look at the max value up to index\n",
    "        df['max_score'] = df['score'].expanding().max()\n",
    "        # when a value changes, calculate the test error \n",
    "        score_changes = df['max_score'].diff().ne(0)\n",
    "        top_score_rows = df[score_changes]\n",
    "        top_score_dicts = top_score_rows.to_dict('records')\n",
    "        nures =  op.gridsearch(eval, parameters , tasks = top_score_dicts , data= test_sets[i], mp=True) \n",
    "\n",
    "\n",
    "        def outer_pointget():\n",
    "            idx = -1\n",
    "            def pointget(z):\n",
    "                nonlocal idx\n",
    "                if z:\n",
    "                    idx += 1\n",
    "                return nures['score'][idx]\n",
    "            return pointget\n",
    "        pointget= outer_pointget()     \n",
    "        df['test_score'] = [ pointget(e) for e in score_changes ] \n",
    "\n",
    "train_test_error(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad507c9-5e02-4f50-bd87-93a6e0090365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a lineplot \n",
    "sns.set_theme()\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "merged_df = pd.concat(results)\n",
    "sns.lineplot(data = merged_df,x=merged_df.index, y = 'max_score', label ='train score')\n",
    "sns.lineplot(data = merged_df,x=merged_df.index, y = 'test_score', label ='test score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69093295-448d-4d72-8c2b-60b266861086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = merged_df\n",
    "top_score_idx = df['score'].idxmax()\n",
    "top_score_row = df.loc[top_score_idx]\n",
    "top_score_dict = top_score_row.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38e4c7-90a0-4439-a790-550ee8b7c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b074a05-f88f-4c24-91cd-3d7640e5ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x = 5\n",
    "\n",
    "top_dfs = [df.sort_values('score', ascending=False).head(x) for df in results]\n",
    "merged_df = pd.concat(top_dfs)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a452431-3014-4f7a-8fa8-c932b4c02970",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat(results)\n",
    "merged_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f8e781-c18d-4747-81a0-5cffe4415044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('min_r')['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e58b47-db5e-4519-9960-5d0a1482fb47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22f15a8378267c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optihelper as oh\n",
    "data = oh.makedata(8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6e5eab2fa81d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd2151f17cb7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = oh.run(data)\n",
    "ax = oh.plot(oh.fixdata(res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d42cee528b7857",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "figpath =  !echo $HOME/pigplot/\n",
    "figpath = figpath[0]\n",
    "\n",
    "\n",
    "ax = oh.plot(oh.fixdata(res))\n",
    "ax.get_figure().savefig(figpath+'hyperparams.png', bbox_inches='tight')\n",
    "\n",
    "if False:\n",
    "    # this is interesting but just confusing\n",
    "    moredata = oh.nosamplingdata()\n",
    "    sns.scatterplot(data=moredata, x='experiment', y='score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7810c98e-d52b-4cc5-bf65-3298c6af9930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd15c2-1514-4bb7-b5ae-04d9185c3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "iris = results[results.min_r != 3]\n",
    "\n",
    "\n",
    "\n",
    "g = sns.PairGrid(iris)\n",
    "\n",
    "# Function to bin and average hue\n",
    "def binned_avg_hue(x, y, hue, bins=15, **kwargs):\n",
    "    if len(x) < 2: return\n",
    "\n",
    "    # 2D histogram binning\n",
    "    df = pd.DataFrame({'x': x, 'y': y, 'hue': hue})\n",
    "    xbins = np.linspace(x.min(), x.max(), bins)\n",
    "    ybins = np.linspace(y.min(), y.max(), bins)\n",
    "    \n",
    "    df['x_bin'] = np.digitize(df['x'], xbins)\n",
    "    df['y_bin'] = np.digitize(df['y'], ybins)\n",
    "    \n",
    "    grouped = df.groupby(['x_bin', 'y_bin'])['hue'].mean().reset_index()\n",
    "    \n",
    "    # Convert bin indexes to bin centers\n",
    "    grouped['x'] = xbins[grouped['x_bin'] - 1]\n",
    "    grouped['y'] = ybins[grouped['y_bin'] - 1]\n",
    "\n",
    "    # Normalize hue to [0,1] for colormap\n",
    "    norm = Normalize(vmin=iris.score.min(), vmax=iris.score.max())\n",
    "    plt.scatter(grouped['x'], grouped['y'], c=grouped['hue'], cmap='viridis', norm=norm, s=50)\n",
    "\n",
    "# Apply to lower triangle\n",
    "g.map_lower(lambda x, y, **kwargs: binned_avg_hue(x, y, iris.score, **kwargs))\n",
    "\n",
    "# Optional: diagonal and upper\n",
    "g.map_diag(sns.histplot)\n",
    "g.map_upper(sns.scatterplot, hue=iris.score)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d8033-5c74-4ad8-8d5d-c8f546834fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.sort_values(by = 'score', ascending = False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d122cfbb-cae6-4127-aebb-d086214c2829",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.sort_values(by = 'score', ascending = False)[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443bce09-f24c-431f-8a74-dd1d300c26b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Braille dot encoding lookup\n",
    "# Each Braille character is a 2x4 dot matrix:\n",
    "# Dot positions:\n",
    "# 1 4\n",
    "# 2 5\n",
    "# 3 6\n",
    "# 7 8\n",
    "DOT_POS = {\n",
    "    (0, 0): 0, (0, 1): 1, (0, 2): 2, (0, 3): 6,\n",
    "    (1, 0): 3, (1, 1): 4, (1, 2): 5, (1, 3): 7\n",
    "}\n",
    "\n",
    "def plot_braille(x, y, rows=20, cols=40):\n",
    "    if len(x) != len(y):\n",
    "        raise ValueError(\"x and y must be the same length\")\n",
    "\n",
    "    # Scale data into pixel coordinates (cols*2 wide, rows*4 tall)\n",
    "    x = np.asarray(x)\n",
    "    y = -np.asarray(y)\n",
    "\n",
    "    # 2x4 pixel grid per Braille character\n",
    "    width_px = cols * 2\n",
    "    height_px = rows * 4\n",
    "\n",
    "    x_bins = np.linspace(np.min(x), np.max(x), width_px + 1)\n",
    "    y_bins = np.linspace(np.min(y), np.max(y), height_px + 1)\n",
    "\n",
    "    x_idx = np.digitize(x, x_bins) - 1\n",
    "    y_idx = np.digitize(y, y_bins) - 1\n",
    "\n",
    "    # Clamp to grid bounds\n",
    "    x_idx = np.clip(x_idx, 0, width_px - 1)\n",
    "    y_idx = np.clip(y_idx, 0, height_px - 1)\n",
    "\n",
    "    \n",
    "    # Initialize Braille canvas\n",
    "    canvas = np.zeros((rows, cols), dtype=np.uint8)\n",
    "\n",
    "    for xi, yi in zip(x_idx, y_idx):\n",
    "        char_col = xi // 2\n",
    "        char_row = yi // 4\n",
    "        dot_col = xi % 2\n",
    "        dot_row = yi % 4\n",
    "\n",
    "        dot_bit = DOT_POS[(dot_col, dot_row)]\n",
    "        canvas[char_row, char_col] |= (1 << dot_bit)\n",
    "\n",
    "    chars = [[\"\".join(chr(0x2800 + cell) if cell else ' ' for cell in row)] for row in canvas]\n",
    "    return chars\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    import math\n",
    "    x_vals = np.linspace(0, 4 * math.pi, 16)\n",
    "    y_vals = np.sin(x_vals)\n",
    "\n",
    "    x = [0.11966315947618589, 0.12776516850249564, 0.13586717752880537, 0.14396918655511512, 0.15207119558142485, 0.1601732046077346, 0.16827521363404435, 0.1763772226603541, 0.18447923168666383, 0.19258124071297356, 0.2006832497392833, 0.20878525876559306, 0.21688726779190282, 0.22498927681821254, 0.2330912858445223, 0.24119329487083202, 0.24929530389714177, 0.2573973129234515, 0.2654993219497612, 0.273601330976071, 0.28170334000238073, 0.2898053490286905, 0.29790735805500024, 0.30600936708131, 0.31411137610761974, 0.3222133851339295, 0.3303153941602392, 0.33841740318654895, 0.3465194122128587, 0.3546214212391684, 0.36272343026547815, 0.3708254392917879, 0.37892744831809766, 0.3870294573444074, 0.39513146637071717, 0.40323347539702686, 0.4113354844233366, 0.41943749344964637, 0.4275395024759561, 0.4356415115022659, 0.4437435205285756, 0.45184552955488533, 0.4599475385811951, 0.46804954760750483, 0.4761515566338146, 0.48425356566012434, 0.49235557468643404, 0.5004575837127438, 0.5085595927390536, 0.5166616017653634] \n",
    "    y= [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 1, 1, 2, 1, 2, 3, 2, 1, 6, 4 ,5, 6, 2, 4, 2, 0, 3, 3, 2, 4, 1, 0, 1, 0, 0, 2, 0, 0, 1]\n",
    "\n",
    "    print(plot_braille(x_vals, y_vals, rows=2, cols=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a463157-1d63-437d-83ad-97f4404004c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import structout as so\n",
    "x = [0.11966315947618589, 0.12776516850249564, 0.13586717752880537, 0.14396918655511512, 0.15207119558142485, 0.1601732046077346, 0.16827521363404435, 0.1763772226603541, 0.18447923168666383, 0.19258124071297356, 0.2006832497392833, 0.20878525876559306, 0.21688726779190282, 0.22498927681821254, 0.2330912858445223, 0.24119329487083202, 0.24929530389714177, 0.2573973129234515, 0.2654993219497612, 0.273601330976071, 0.28170334000238073, 0.2898053490286905, 0.29790735805500024, 0.30600936708131, 0.31411137610761974, 0.3222133851339295, 0.3303153941602392, 0.33841740318654895, 0.3465194122128587, 0.3546214212391684, 0.36272343026547815, 0.3708254392917879, 0.37892744831809766, 0.3870294573444074, 0.39513146637071717, 0.40323347539702686, 0.4113354844233366, 0.41943749344964637, 0.4275395024759561, 0.4356415115022659, 0.4437435205285756, 0.45184552955488533, 0.4599475385811951, 0.46804954760750483, 0.4761515566338146, 0.48425356566012434, 0.49235557468643404, 0.5004575837127438, 0.5085595927390536, 0.5166616017653634] \n",
    "y= [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 1, 1, 2, 1, 2, 3, 2, 1, 6, 4 ,5, 6, 2, 4, 2, 0, 3, 3, 2, 4, 1, 0, 1, 0, 0, 2, 0, 0, 1]\n",
    "so.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc915b-ddba-427b-8c50-c9f737d1788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def convert_to_custom_grayscale(image_path, output_path=''):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_np = np.array(img)\n",
    "    R = img_np[:,:,0].astype(float)\n",
    "    G = img_np[:,:,1].astype(float)\n",
    "    B = img_np[:,:,2].astype(float)\n",
    "    # grayscale = B - (R + G) / 2\n",
    "    grayscale = B *2 - R -G\n",
    "    grayscale[grayscale < 0] =0\n",
    "    grayscale_norm = grayscale\n",
    "    #grayscale_norm = grayscale_norm.astype(np.uint8)\n",
    "    grayscale_img = Image.fromarray(grayscale_norm)\n",
    "    #grayscale_img.show()\n",
    "    #grayscale_img.save('/home/ikea/test.png')\n",
    "\n",
    "    \n",
    "    rgb_array = np.stack([grayscale_norm]*3, axis=-1)  # Stack grayscale as R, G, B\n",
    "    \n",
    "    # Convert to PIL Image with RGB mode\n",
    "    rgb_img = Image.fromarray(rgb_array, 'RGB')\n",
    "    \n",
    "    # Save the image\n",
    "    path = '/home/ikea/output_rgb.png'\n",
    "\n",
    "\n",
    "    grayscale_norm = grayscale_norm.astype(np.uint8)  # Convert to uint8\n",
    "    grayscale_img = Image.fromarray(grayscale_norm)\n",
    "    grayscale_img.save(path, 'PNG')\n",
    "convert_to_custom_grayscale('/home/ikea/Downloads/5402504650445420277.jpg')\n",
    "# convert_to_custom_grayscale('/home/ikea/Downloads/5402504650445420230.jpg')\n",
    "#convert_to_custom_grayscale('/home/ikea/Downloads/5402504650445420231.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02680582-2ad2-4c95-9ad1-18507f77a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def plot_pca_of_image_colors(image_path, sample_fraction=0.1, n_components=3):\n",
    "    \"\"\"\n",
    "    Loads an image, performs PCA on its RGB pixel data, and creates a 2D scatter plot\n",
    "    of the transformed data, colored by the original pixel colors.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The file path to the input image.\n",
    "        sample_fraction (float, optional): The fraction of pixels to sample for analysis. \n",
    "                                           1.0 means all pixels. Defaults to 0.1 (10%) for performance.\n",
    "        n_components (int, optional): The number of principal components to reduce to. Defaults to 2.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Load the image and convert to an RGB numpy array\n",
    "        with Image.open(image_path) as img:\n",
    "            # Ensure image is in RGB format\n",
    "            img_rgb = img.convert('RGB')\n",
    "            img_np = np.array(img_rgb)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {image_path} was not found.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while opening the image: {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. Prepare the data for PCA\n",
    "    # Reshape the (height, width, 3) image array into a (num_pixels, 3) array\n",
    "    # where each row is a pixel and columns are R, G, B.\n",
    "    h, w, c = img_np.shape\n",
    "    pixel_data = img_np.reshape(-1, c)\n",
    "    print(f\"Image loaded: {w}x{h} ({h*w:,} pixels)\")\n",
    "    \n",
    "    # 3. Sample the data for performance if needed\n",
    "    if sample_fraction < 1.0:\n",
    "        num_pixels = pixel_data.shape[0]\n",
    "        sample_size = int(num_pixels * sample_fraction)\n",
    "        print(f\"Sampling {sample_size:,} pixels ({sample_fraction * 100:.1f}%) for performance...\")\n",
    "        # Generate random indices without replacement\n",
    "        random_indices = np.random.choice(num_pixels, size=sample_size, replace=False)\n",
    "        # Select the sampled pixels\n",
    "        pixel_data_sampled = pixel_data[random_indices]\n",
    "    else:\n",
    "        pixel_data_sampled = pixel_data\n",
    "\n",
    "    # 4. Perform PCA\n",
    "    print(\"Performing PCA...\")\n",
    "    pca = PCA(n_components=n_components)\n",
    "    # Fit PCA on the sampled pixel data and transform it\n",
    "    transformed_data = pca.fit_transform(pixel_data_sampled)\n",
    "    \n",
    "    # Explained variance tells us how much information each component captures\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    print(f\"Explained variance by components: {explained_variance}\")\n",
    "    print(f\"Total variance explained by {n_components} components: {sum(explained_variance)*100:.2f}%\")\n",
    "\n",
    "    # 5. Prepare colors for plotting\n",
    "    # The `c` argument in matplotlib's scatter expects colors to be in the [0, 1] range.\n",
    "    # We use the original colors of the sampled pixels.\n",
    "    colors_for_plot = pixel_data_sampled / 255.0\n",
    "\n",
    "    # 6. Plot the results\n",
    "    print(\"Generating plot...\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    ax.scatter(\n",
    "        transformed_data[:, 0], \n",
    "        transformed_data[:, 1], \n",
    "        c=colors_for_plot,\n",
    "        alpha=1, # Use transparency to see density\n",
    "        s=5        # Use small markers\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f'2D PCA of Image Color Space ({image_path.split(\"/\")[-1]})')\n",
    "    ax.set_xlabel(f'Principal Component 1 ({explained_variance[0]*100:.2f}% variance)')\n",
    "    ax.set_ylabel(f'Principal Component 2 ({explained_variance[1]*100:.2f}% variance)')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.scatter(\n",
    "        transformed_data[:, 2], \n",
    "        transformed_data[:, 1], \n",
    "        c=colors_for_plot,\n",
    "        alpha=1, # Use transparency to see density\n",
    "        s=5        # Use small markers\n",
    "    )\n",
    "    plt.show()\n",
    "   \n",
    "\n",
    "plot_pca_of_image_colors('/home/ikea/Downloads/5402504650445420277.jpg')\n",
    "plot_pca_of_image_colors('/home/ikea/Downloads/5402504650445420230.jpg')\n",
    "plot_pca_of_image_colors('/home/ikea/Downloads/5402504650445420231.jpg')\n",
    "plot_pca_of_hsv_colors('/home/ikea/Downloads/pudding.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8e4522-ce67-4e1f-be04-ec33585fcfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def reconstruct_image_without_pc(image_path, component_to_remove=2, output_path=None):\n",
    "    \"\"\"\n",
    "    Loads an image, performs PCA on its colors, removes a specified principal\n",
    "    component, and reconstructs the image from the modified data.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The file path to the input image.\n",
    "        component_to_remove (int): The index of the principal component to remove (0, 1, or 2).\n",
    "                                   Defaults to 1 (which is PC2).\n",
    "        output_path (str, optional): If provided, saves the reconstructed image to this path.\n",
    "                                     Defaults to None.\n",
    "    \"\"\"\n",
    "    if not 0 <= component_to_remove <= 2:\n",
    "        print(\"Error: component_to_remove must be 0, 1, or 2.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # 1. Load the image and get pixel data\n",
    "        with Image.open(image_path) as img:\n",
    "            img_rgb = img.convert('RGB')\n",
    "            img_np = np.array(img_rgb)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {image_path} was not found.\")\n",
    "        return\n",
    "\n",
    "    # Store original shape and data type for reconstruction\n",
    "    h, w, c = img_np.shape\n",
    "    original_dtype = img_np.dtype\n",
    "    \n",
    "    # Reshape for PCA: (num_pixels, 3)\n",
    "    pixel_data = img_np.reshape(-1, c)\n",
    "    print(f\"Image loaded: {w}x{h}. Processing {pixel_data.shape[0]:,} pixels.\")\n",
    "\n",
    "    # 2. Perform PCA\n",
    "    # We need all 3 components to do a full inverse transform\n",
    "    print(\"Fitting PCA...\")\n",
    "    pca = PCA(n_components=3)\n",
    "    \n",
    "    # Fit and then transform the data into the PCA coordinate space\n",
    "    transformed_data = pca.fit_transform(pixel_data)\n",
    "\n",
    "    # 3. Modify the data by \"removing\" the specified component\n",
    "    print(f\"Removing Principal Component {component_to_remove + 1}...\")\n",
    "    # Create a copy to avoid modifying the original transformed data\n",
    "    modified_data = transformed_data.copy()\n",
    "    # Set the entire column for the chosen component to zero\n",
    "    modified_data[:, component_to_remove] = 0\n",
    "\n",
    "    # 4. Inverse transform back to RGB space\n",
    "    print(\"Reconstructing image from modified data...\")\n",
    "    # Use the inverse_transform method to go from PCA space back to RGB space\n",
    "    reconstructed_pixels = pca.inverse_transform(modified_data)\n",
    "\n",
    "    # 5. Reshape and format the image for display\n",
    "    # Clip values to the valid [0, 255] range for colors\n",
    "    reconstructed_pixels = np.clip(reconstructed_pixels, 0, 255)\n",
    "    \n",
    "    # Reshape back to the original image dimensions\n",
    "    reconstructed_img_np = reconstructed_pixels.reshape(h, w, c)\n",
    "    \n",
    "    # Convert back to the original data type (e.g., uint8)\n",
    "    reconstructed_img_np = reconstructed_img_np.astype(original_dtype)\n",
    "    \n",
    "    # Convert the numpy array to a PIL Image object\n",
    "    reconstructed_img = Image.fromarray(reconstructed_img_np)\n",
    "\n",
    "    # 6. Display the results\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    axes[0].imshow(img_rgb)\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(reconstructed_img)\n",
    "    axes[1].set_title(f\"Reconstructed (PC{component_to_remove + 1} Removed)\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 7. Save the image if an output path is provided\n",
    "    if output_path:\n",
    "        reconstructed_img.save(output_path)\n",
    "        print(f\"Reconstructed image saved to {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reconstruct_image_without_pc('/home/ikea/Downloads/5402504650445420277.jpg')\n",
    "reconstruct_image_without_pc('/home/ikea/Downloads/5402504650445420230.jpg')\n",
    "reconstruct_image_without_pc('/home/ikea/Downloads/5402504650445420231.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9fac04-e971-49a5-9493-a3db63204a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def rgb_to_hsv_manual(rgb_image):\n",
    "    \"\"\"Converts an RGB image (NumPy array) to HSV format manually.\"\"\"\n",
    "    rgb_norm = rgb_image.astype(float) / 255.0\n",
    "    R, G, B = rgb_norm[:,:,0], rgb_norm[:,:,1], rgb_norm[:,:,2]\n",
    "    V = np.max(rgb_norm, axis=2)\n",
    "    min_val = np.min(rgb_norm, axis=2)\n",
    "    delta = V - min_val\n",
    "    S = np.where(V == 0, 0, delta / V)\n",
    "    H = np.zeros_like(V)\n",
    "    mask_delta = delta != 0\n",
    "    mask_R = (V == R) & mask_delta\n",
    "    mask_G = (V == G) & mask_delta\n",
    "    mask_B = (V == B) & mask_delta\n",
    "    H[mask_R] = 60 * (((G[mask_R] - B[mask_R]) / delta[mask_R]))\n",
    "    H[mask_G] = 60 * (2 + (B[mask_G] - R[mask_G]) / delta[mask_G])\n",
    "    H[mask_B] = 60 * (4 + (R[mask_B] - G[mask_B]) / delta[mask_B])\n",
    "    H[H < 0] += 360\n",
    "    hsv_image = np.stack([H, S, V], axis=-1)\n",
    "    return hsv_image\n",
    "\n",
    "def plot_pca_of_hsv_colors(image_path, sample_fraction=0.1):\n",
    "    \"\"\"\n",
    "    Loads an image, converts it to HSV, performs PCA on the HSV data,\n",
    "    and creates a 2D scatter plot colored by the original RGB values.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The file path to the input image.\n",
    "        sample_fraction (float, optional): Fraction of pixels to sample for performance.\n",
    "                                           Defaults to 0.1 (10%).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Load the image and get original RGB data\n",
    "        with Image.open(image_path) as img:\n",
    "            img_rgb = img.convert('RGB')\n",
    "            img_np_rgb = np.array(img_rgb)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {image_path} was not found.\")\n",
    "        return\n",
    "\n",
    "    print(\"Converting image from RGB to HSV...\")\n",
    "    # 2. Convert the image to HSV\n",
    "    img_np_hsv = rgb_to_hsv_manual(img_np_rgb)\n",
    "    \n",
    "    # 3. Prepare the data for PCA\n",
    "    # Reshape both RGB (for color) and HSV (for PCA) data\n",
    "    h, w, _ = img_np_rgb.shape\n",
    "    rgb_pixels = img_np_rgb.reshape(-1, 3)\n",
    "    hsv_pixels = img_np_hsv.reshape(-1, 3)\n",
    "    print(f\"Image loaded: {w}x{h} ({h*w:,} pixels)\")\n",
    "    \n",
    "    # 4. Sample the data for performance\n",
    "    # It is CRITICAL to use the same random indices for both HSV and RGB data\n",
    "    if sample_fraction < 1.0:\n",
    "        num_pixels = rgb_pixels.shape[0]\n",
    "        sample_size = int(num_pixels * sample_fraction)\n",
    "        print(f\"Sampling {sample_size:,} pixels ({sample_fraction * 100:.1f}%)...\")\n",
    "        random_indices = np.random.choice(num_pixels, size=sample_size, replace=False)\n",
    "        \n",
    "        # Sample both datasets using the same indices\n",
    "        hsv_sampled = hsv_pixels[random_indices]\n",
    "        rgb_sampled_for_color = rgb_pixels[random_indices]\n",
    "    else:\n",
    "        hsv_sampled = hsv_pixels\n",
    "        rgb_sampled_for_color = rgb_pixels\n",
    "\n",
    "    # 5. Perform PCA on the HSV data\n",
    "    print(\"Performing PCA on HSV data...\")\n",
    "    pca = PCA(n_components=3)\n",
    "    transformed_hsv_data = pca.fit_transform(hsv_sampled)\n",
    "    \n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    print(f\"Explained variance by components (from HSV): {explained_variance}\")\n",
    "    print(f\"Total variance explained by 2 components: {sum(explained_variance)*100:.2f}%\")\n",
    "    \n",
    "    # 6. Prepare original RGB colors for plotting\n",
    "    colors_for_plot = rgb_sampled_for_color / 255.0\n",
    "\n",
    "    # 7. Plot the results\n",
    "    print(\"Generating plot...\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    ax.scatter(\n",
    "        transformed_hsv_data[:, 0], \n",
    "        transformed_hsv_data[:, 1], \n",
    "        c=colors_for_plot,\n",
    "        alpha=0.5,\n",
    "        s=5\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f'2D PCA of HSV Color Space ({image_path.split(\"/\")[-1]})')\n",
    "    ax.set_xlabel(f'Principal Component 1 (from HSV) ({explained_variance[0]*100:.2f}% variance)')\n",
    "    ax.set_ylabel(f'Principal Component 2 (from HSV) ({explained_variance[1]*100:.2f}% variance)')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    plt.scatter(\n",
    "        transformed_hsv_data[:, 2], \n",
    "        transformed_hsv_data[:, 1], \n",
    "        c=colors_for_plot,\n",
    "        alpha=0.5,\n",
    "        s=5\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_pca_of_hsv_colors('/home/ikea/Downloads/5402504650445420277.jpg')\n",
    "plot_pca_of_hsv_colors('/home/ikea/Downloads/5402504650445420230.jpg')\n",
    "plot_pca_of_hsv_colors('/home/ikea/Downloads/5402504650445420231.jpg')\n",
    "plot_pca_of_hsv_colors('/home/ikea/Downloads/pudding.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0417e364-75f1-468e-81bd-f98f1cbf8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rgb_to_hsv_manual(rgb_image):\n",
    "    \"\"\"Converts an RGB image (NumPy array) to HSV format manually.\"\"\"\n",
    "    rgb_norm = rgb_image.astype(float) / 255.0\n",
    "    R, G, B = rgb_norm[:,:,0], rgb_norm[:,:,1], rgb_norm[:,:,2]\n",
    "    V = np.max(rgb_norm, axis=2)\n",
    "    min_val = np.min(rgb_norm, axis=2)\n",
    "    delta = V - min_val\n",
    "    S = np.where(V == 0, 0, delta / V)\n",
    "    H = np.zeros_like(V)\n",
    "    mask_delta = delta != 0\n",
    "    mask_R = (V == R) & mask_delta\n",
    "    mask_G = (V == G) & mask_delta\n",
    "    mask_B = (V == B) & mask_delta\n",
    "    H[mask_R] = 60 * (((G[mask_R] - B[mask_R]) / delta[mask_R]))\n",
    "    H[mask_G] = 60 * (2 + (B[mask_G] - R[mask_G]) / delta[mask_G])\n",
    "    H[mask_B] = 60 * (4 + (R[mask_B] - G[mask_B]) / delta[mask_B])\n",
    "    H[H < 0] += 360\n",
    "    hsv_image = np.stack([H, S, V], axis=-1)\n",
    "    return hsv_image\n",
    "\n",
    "def plot_saturation_grayscale(image_path):\n",
    "    \"\"\"\n",
    "    Loads an image, converts it to HSV, and displays the original image next to\n",
    "    a grayscale image created from its saturation channel.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The file path to the input image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Load the image and convert to an RGB numpy array\n",
    "        with Image.open(image_path) as img:\n",
    "            img_rgb = img.convert('RGB')\n",
    "            img_np_rgb = np.array(img_rgb)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {image_path} was not found.\")\n",
    "        return\n",
    "\n",
    "    # 2. Convert the image to HSV\n",
    "    print(\"Converting RGB to HSV...\")\n",
    "    img_np_hsv = rgb_to_hsv_manual(img_np_rgb)\n",
    "    \n",
    "    # 3. Isolate the Saturation channel\n",
    "    # In our HSV array, S is the second channel (index 1)\n",
    "    saturation_channel = img_np_hsv[:, :, 1]\n",
    "    \n",
    "    # 4. Create a displayable grayscale image from the saturation data\n",
    "    # The saturation channel is in the range [0.0, 1.0]. We scale it to [0, 255]\n",
    "    # and convert it to an 8-bit integer type for image display.\n",
    "    saturation_gray_np = (saturation_channel * 255).astype(np.uint8)\n",
    "    \n",
    "    # Convert the 2D NumPy array into a PIL Image object\n",
    "    saturation_img = Image.fromarray(saturation_gray_np)\n",
    "\n",
    "    # 5. Plot the original and the saturation-grayscale image side-by-side\n",
    "    print(\"Generating plot...\")\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    axes[0].imshow(img_rgb)\n",
    "    axes[0].set_title(\"Original RGB Image\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Use cmap='gray' to ensure it's displayed as a proper grayscale image\n",
    "    axes[1].imshow(saturation_img, cmap='gray', vmin=0, vmax=255)\n",
    "    axes[1].set_title(\"Saturation as Grayscale\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- HOW TO USE IT ---\n",
    "image_path = \"test_color_image.png\"\n",
    "try:\n",
    "    # Ensure the test image exists\n",
    "    Image.open(image_path)\n",
    "except FileNotFoundError:\n",
    "    print(\"Creating a test image...\")\n",
    "    # This image is designed to show high and low saturation clearly\n",
    "    test_img_array = np.zeros((100, 300, 3), dtype=np.uint8)\n",
    "    test_img_array[:, :100] = [255, 10, 10]    # Saturated Red\n",
    "    test_img_array[:, 100:200] = [128, 128, 128] # Gray (No Saturation)\n",
    "    test_img_array[:, 200:] = [255, 200, 200]  # Pale Pink (Low Saturation)\n",
    "    Image.fromarray(test_img_array).save(image_path)\n",
    "    \n",
    "# Run the function on the test image\n",
    "plot_saturation_grayscale('/home/ikea/Downloads/plate.jpg')\n",
    "plot_saturation_grayscale('/home/ikea/Downloads/5402504650445420277.jpg')\n",
    "plot_saturation_grayscale('/home/ikea/Downloads/5402504650445420230.jpg')\n",
    "plot_saturation_grayscale('/home/ikea/Downloads/5402504650445420231.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
